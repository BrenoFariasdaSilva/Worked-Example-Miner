import atexit # For playing a sound when the program finishes
import concurrent.futures # For running tasks in parallel
import csv # CSV (Comma Separated Values) is a simple file format used to store tabular data, such as a spreadsheet or database
import json # JSON (JavaScript Object Notation) is a lightweight data-interchange format
import os # OS module in Python provides functions for interacting with the operating system
import pandas as pd # Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool
import subprocess # The subprocess module allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes
import time # This module provides various time-related functions
from colorama import Style # For coloring the terminal
from datetime import datetime # For date manipulation
from pydriller import Repository # PyDriller is a Python framework that helps developers in analyzing Git repositories. 
from tqdm import tqdm # For Generating the Progress Bars

# Imports from the repositories_picker.py file
from repositories_picker import BackgroundColors # Import the BackgroundColors class
from repositories_picker import DEFAULT_REPOSITORIES, FULL_REPOSITORIES_DIRECTORY_PATH, RELATIVE_REPOSITORIES_DIRECTORY_PATH, SOUND_FILE_PATH, START_PATH # Importing Constants from the repositories_picker.py file
from repositories_picker import count_commits, create_directory, get_adjusted_number_of_threads, get_threads, output_time, path_contains_whitespaces, play_sound, setup_repository, update_sound_file_path, verbose_output, verify_filepath_exists, verify_git, verify_repositories_execution_constants # Importing Functions from the repositories_picker.py file

# Default values that can be changed:
VERBOSE = False # Verbose mode. If set to True, it will output messages at the start/call of each function (Note: It will output a lot of messages).

RUN_FUNCTIONS = { # Dictionary with the functions to run and their respective booleans
   "generate_diffs": False, # Generate the diffs for the commits
   "write_commits_information_to_csv": True, # Write the commit information to a CSV file
   "write_repositories_attributes_to_csv": True, # Write the repositories attributes to a CSV file
}

# File Extensions Constants:
CSV_FILE_EXTENSION = ".csv" # The extension of the file that contains the commit hashes
DIFF_FILE_EXTENSION = ".diff" # The diff file extension

# CK Constants:
CK_BRANCH = "FEAT-ClassMetric" # The branch of the CK repository to be used
CK_METRICS_FILES = ["class.csv", "method.csv"] # The files that are generated by CK

# Relative paths:
RELATIVE_CK_SUBMODULE_PATH = "../ck" # The relative path of the CK submodule
RELATIVE_CK_JAR_PATH = f"{RELATIVE_CK_SUBMODULE_PATH}/target/ck-0.7.1-SNAPSHOT-jar-with-dependencies.jar" # The relative path of the CK JAR file
RELATIVE_CK_METRICS_DIRECTORY_PATH = "/ck_metrics" # The relative path of the directory that contains the CK generated files
RELATIVE_DIFFS_DIRECTORY_PATH = "/diffs" # The relative path of the directory that contains the diffs
RELATIVE_PROGRESS_DIRECTORY_PATH = "/progress" # The relative path of the progress file
RELATIVE_REFACTORINGS_DIRECTORY_PATH = "/refactorings" # The relative path of the directory that contains the refactorings
RELATIVE_REPOSITORIES_ATTRIBUTES_FILE_PATH = f"{RELATIVE_REPOSITORIES_DIRECTORY_PATH}/repositories_attributes{CSV_FILE_EXTENSION}" # The relative path of the file that contains the repositories attributes
RELATIVE_REPOSITORY_PROGRESS_FILE_PATH = f"{RELATIVE_REPOSITORIES_DIRECTORY_PATH}/repository_name-progress{CSV_FILE_EXTENSION}" # The relative path of the file that contains the repository progress

# Full paths (Start Path + Relative Paths):
FULL_CK_JAR_PATH = START_PATH.replace("PyDriller", "") + RELATIVE_CK_JAR_PATH.replace("../", "") # The full path of the CK JAR file
FULL_CK_METRICS_DIRECTORY_PATH = START_PATH + RELATIVE_CK_METRICS_DIRECTORY_PATH # The full path of the directory that contains the CK generated files
FULL_DIFFS_DIRECTORY_PATH = START_PATH + RELATIVE_DIFFS_DIRECTORY_PATH # The full path of the directory that contains the diffs
FULL_PROGRESS_DIRECTORY_PATH = START_PATH + RELATIVE_PROGRESS_DIRECTORY_PATH # The full path of the progress file
FULL_REFACTORINGS_DIRECTORY_PATH = START_PATH + RELATIVE_REFACTORINGS_DIRECTORY_PATH # The full path of the directory that contains the refactorings
FULL_REPOSITORIES_ATTRIBUTES_FILE_PATH = START_PATH + RELATIVE_REPOSITORIES_ATTRIBUTES_FILE_PATH # The full path of the file that contains the repositories attributes
FULL_REPOSITORY_PROGRESS_FILE_PATH = START_PATH + RELATIVE_REPOSITORY_PROGRESS_FILE_PATH # The full path of the file that contains the repository progress
OUTPUT_DIRECTORIES = [FULL_CK_METRICS_DIRECTORY_PATH, FULL_DIFFS_DIRECTORY_PATH, FULL_REPOSITORIES_DIRECTORY_PATH] # The list of output directories

def init_and_update_submodules():
   """
   Initialize and update Git submodules

   :return: True if the Git submodules were initialized and updated successfully, False otherwise.
   """

   try:
      verbose_output(true_string=f"{BackgroundColors.GREEN}Initializing and updating the CK Git Submodule...{Style.RESET_ALL}")

      # Adjust path as necessary for reliability across environments
      submodule_path = os.path.abspath(f"{RELATIVE_CK_SUBMODULE_PATH}/.git") # Path to the ck submodule

      if not verify_filepath_exists(submodule_path): # If the submodule path does not exist
         subprocess.run(["git", "submodule", "init"], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) # Initialize the Git submodule
         subprocess.run(["git", "submodule", "update"], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) # Update the Git submodule
      else:
         subprocess.run(["git", "submodule", "update", "--remote"], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) # Update the Git submodule
   except subprocess.CalledProcessError as e:
      print(f"{BackgroundColors.RED}An error occurred while initializing and updating the CK Git Submodule: {e}{Style.RESET_ALL}")
      return False # Return False if the Git submodules could not be initialized and updated
   return True # Return True if the Git submodules were initialized and updated successfully

def get_current_branch(repo_path):
   """
   Retrieve the current branch of the repository at the specified path.
   
   :param repo_path: Path to the repository
   :return: The name of the current branch
   """

   result = subprocess.run(["git", "rev-parse", "--abbrev-ref", "HEAD"], cwd=repo_path, capture_output=True, text=True) # Run the Git command to get the current branch
   return result.stdout.strip() # Get the current branch

def switch_branch(target_branch, repo_path):
   """
   Switch branches in the specified repository.
   
   :param target_branch: The name of the target branch
   :param repo_path: Path to the repository
   :return: True if the branch was successfully switched, False otherwise
   """
   
   try:
      subprocess.run(["git", "checkout", target_branch], cwd=repo_path, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) # Switch to the target branch
      verbose_output(true_string=f"{BackgroundColors.GREEN}Successfully switched to {BackgroundColors.CYAN}{target_branch}{BackgroundColors.GREEN} branch.{Style.RESET_ALL}")
      return True # Return True if the branch was successfully switched
   except subprocess.CalledProcessError:
      print(f"{BackgroundColors.RED}Failed to switch to {BackgroundColors.GREEN}{target_branch}{BackgroundColors.RED} branch.{Style.RESET_ALL}")
      return False # Return False if the branch could not be switched

def build_ck_jar_file(repo_path):
   """
   Build the CK JAR file if it doesn't already exist.
   
   :param repo_path: Path to the ck submodule
   :return: True if the JAR file was successfully built, False otherwise
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Building the CK JAR file...{Style.RESET_ALL}")
   subprocess.run(["mvn", "clean", "package", "-DskipTests"], cwd=repo_path, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) # Build the CK JAR file
   return verify_filepath_exists(RELATIVE_CK_JAR_PATH) # Return True if the JAR file exists, False otherwise

def ensure_ck_jar_file_exists():
   """
   Ensure that the CK JAR file exists in the ck directory. If not, build the CK JAR file.
   We don't verify if the CK_JAR already exists in the target directory because we want to ensure that the latest version is used.
   
   :return: True if the CK JAR file was found or built successfully, False otherwise.
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Ensuring that the {BackgroundColors.CYAN}CK JAR{BackgroundColors.GREEN} file exists in the target directory...{Style.RESET_ALL}")

   # Initialize and update Git submodules
   if not init_and_update_submodules():
      return False # Return if the Git submodules could not be initialized and updated

   ck_repo_path = os.path.abspath(RELATIVE_CK_SUBMODULE_PATH) # Path to the ck submodule

   original_branch = get_current_branch(ck_repo_path) # Store the current branch before switching

   if not switch_branch(CK_BRANCH, ck_repo_path): # Try to switch to the desired CK branch if it exists
      # If switching to CK_BRANCH fails, try to switch to a standard branch
      standard_branches = ["master", "main"] # Standard branch names
      for branch in standard_branches: # Loop through the standard branches
         if switch_branch(branch, ck_repo_path): # Try to switch to the standard branch
            original_branch = branch # Successfully switched to a standard branch, use that as the fallback
            break # Exit the loop if a standard branch was found
      else:
         print(f"{BackgroundColors.RED}None of the standard branches {BackgroundColors.CYAN}{', '.join(standard_branches)}{BackgroundColors.RED} exist in {BackgroundColors.CYAN}'ck'{BackgroundColors.RED}. Please verify the repository structure.{Style.RESET_ALL}")
         return False # Return False if no valid branch was found

   if build_ck_jar_file(ck_repo_path): # Build the JAR file if it does not exist
      switch_branch(original_branch, ck_repo_path) # Switch back to the original branch
      if verify_filepath_exists(RELATIVE_CK_JAR_PATH): # Verify if the jar exists in the ck directory
         return True # Return True if the CK JAR file was found in the target directory

   print(f"{BackgroundColors.RED}The {BackgroundColors.CYAN}CK JAR{BackgroundColors.RED} file was not found in the target directory.{Style.RESET_ALL}")
   return False # Return False if the JAR file was not found in the target directory

def get_commit_filepaths(commit_file_path):
   """
   Read the commit information from a CSV file and return a list of file paths in the format '{Commit Number}-{Commit Hash}'.

   :param commit_file_path: Path to the CSV file containing commit details
   :return: List of file paths in the format '{Commit Number}-{Commit Hash}'
   """
   
   if not verify_filepath_exists(commit_file_path): # Verify if the file exists
      return [] # Return an empty list if the file does not exist

   df = pd.read_csv(commit_file_path, sep=",", usecols=["Commit Number", "Commit Hash"], header=0) # Read the CSV file and get the necessary columns
   filepaths = [f"{row['Commit Number']}-{row['Commit Hash']}" for _, row in df.iterrows()] # Create a list of file paths in the format '{Commit Number}-{Commit Hash}'
   
   return filepaths # Return the list of file paths

def verify_ck_metrics_files(folder_path, ck_metrics_files):
   """
   Verify if all the CK metrics files exist inside the specified folder.

   :param folder_path: Path to the folder containing CK metrics files
   :param ck_metrics_files: List of CK metrics file names to check
   :return: True if all CK metrics files exist, False otherwise
   """

   for ck_metric_file in ck_metrics_files: # Loop through the CK metrics files
      ck_metric_file_path = os.path.join(folder_path, ck_metric_file) # Join the folder path with the CK metric file
      if not verify_filepath_exists(ck_metric_file_path): # If the CK metric file does not exist
         return False # Return False if the CK metric file does not exist
   return True # Return True if all CK metrics files exist

def verify_ck_metrics_folder(repository_name):
   """
   Verifies if all the metrics are already calculated by opening the commit hashes file and checking if every commit hash in the file is a folder in the repository folder.

   :param repository_name: Name of the repository to be analyzed.
   :return: True if all the metrics are already calculated, False otherwise.
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Verifying if the metrics for {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} were already calculated...{Style.RESET_ALL}")

   repo_path = os.path.join(FULL_CK_METRICS_DIRECTORY_PATH, repository_name) # Join the full ck metrics directory path with the repository
   commit_file = f"{repository_name}-commits_list{CSV_FILE_EXTENSION}" # The name of the commit hashes file
   commit_file_path = os.path.join(FULL_CK_METRICS_DIRECTORY_PATH, commit_file) # Join the full ck metrics directory path with the commit hashes file

   repository_ck_metrics_filepaths = get_commit_filepaths(commit_file_path) # Get the commit filepaths

   if not repository_ck_metrics_filepaths: # If the filepaths list is empty
      return False # Return False if the filepaths list is empty

   for ck_metrics_filepath in repository_ck_metrics_filepaths: # Loop through the commit hashes
      folder_path = os.path.join(repo_path, ck_metrics_filepath) # Join the repository path with the commit hash folder

      if verify_filepath_exists(folder_path): # Verify if the folder exists
         if not verify_ck_metrics_files(folder_path, CK_METRICS_FILES): # Verify if all the CK metrics files exist
            return False # If any CK metrics file does not exist, return False
      else: # If the folder does not exist
         return False # Return False if the folder does not exist

   return True # Return True if all the metrics are already calculated

def read_progress_file(file_path):
   """
   Read the contents of the progress file

   :param file_path: Path to the saved progress file
   :return: List of lines from the progress file
   """

   if not verify_filepath_exists(file_path): # Verify if the file exists
      return [] # Return an empty list if the file does not exist

   with open(file_path, "r") as file: # Open the progress file
      lines = file.readlines() # Read the lines from the file
   
   return lines # Return the lines from the progress file

def parse_commit_info(lines):
   """
   Parse commit information from the lines of the progress file.

   :param lines: List of lines from the progress file
   :return: Tuple containing the list of commit info, the last commit number and the last commit hash
   """

   commits_info = [] # List to store the commit information
   last_commit_number = 0 # Variable to store the last commit number
   last_commit_hash = None # Variable to store the last commit hash
   
   if len(lines) > 3: # If there are more than 3 lines in the file
      last_commit_number = int(lines[-1].split(",")[0]) # Get the last commit number from the last line
      last_commit_hash = lines[-1].split(",")[1] # Get the last commit hash from the last line
      for line in lines[1:]: # Loop through the lines, excluding the header
         parts = line.split(",") # Split the line by commas
         commit_tuple = tuple(int(parts[i]) if i in (4, 5, 6, 8) else float(parts[i]) if i == 7 else parts[i] for i in range(len(parts))) # Create a tuple with the commit information, converting necessary parts to their respective types
         commits_info.append(commit_tuple) # Append the commit information to the list
   
   return commits_info, last_commit_number, last_commit_hash # Return the commits_info, last_commit_number and last_commit_hash

def calculate_percentage_progress(last_commit_number, total_commits):
   """
   Calculate the percentage progress based on the last commit number.

   :param last_commit_number: The last processed commit number
   :param total_commits: Total number of commits to be processed
   :return: Percentage of progress as a rounded float
   """

   return round((last_commit_number / total_commits) * 100, 2) # Calculate the percentage progress

def write_progress_file(file_path, lines):
   """
   Write the provided lines to the progress file, including the header.

   :param file_path: Path to the saved progress file
   :param lines: List of lines to be written to the file
   """

   with open(file_path, "w") as file: # Open the progress file to write
      file.write("Commit Number,Commit Hash,Commit Message,Commit Date,Lines Added,Lines Removed,Commit Code Churn,Avg Code Churn Per File,Modified Files Count,Commit URL\n")
      for line in lines: # Loop through the lines
         file.write(line) # Write the line to the file

def get_last_execution_progress(repository_name, saved_progress_file, number_of_commits):
   """
   Gets the last execution progress of the repository.

   :param repository_name: Name of the repository to be analyzed.
   :param saved_progress_file: Name of the file that contains the saved progress.
   :param number_of_commits: Number of commits to be analyzed.
   :return: The commits_info and last_commit_number.
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Getting the last execution progress of the {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} repository...{Style.RESET_ALL}")

   lines = read_progress_file(saved_progress_file) # Read the progress file
   commits_info = [] # Initialize the commits_info list
   last_commit_number = 0 # Initialize the last_commit_number variable

   if lines: # If there are lines in the progress file
      commits_info, last_commit_number, last_commit_hash = parse_commit_info(lines) # Parse the commit information
      percentage_progress = calculate_percentage_progress(last_commit_number, number_of_commits) # Calculate the percentage progress
 
      print(f"{BackgroundColors.GREEN}{BackgroundColors.CYAN}{repository_name.capitalize()}{BackgroundColors.GREEN} stopped executing in {BackgroundColors.CYAN}{percentage_progress}%{BackgroundColors.GREEN} of its progress in the {BackgroundColors.CYAN}{last_commit_number}ยบ{BackgroundColors.GREEN} commit: {BackgroundColors.CYAN}{last_commit_hash}{BackgroundColors.GREEN}.{Style.RESET_ALL}")
      
      execution_time = f"{BackgroundColors.GREEN}Estimated time for running the remaining iterations in {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN}: {Style.RESET_ALL}"
      output_time(execution_time, number_of_commits - last_commit_number) # Output the estimated time for running the remaining iterations for the repository
   else:
      write_progress_file(saved_progress_file, commits_info) # If there is no saved progress file, create one and write the header

   return commits_info, last_commit_number # Return the commits_info and last_commit_number

def generate_diffs(repository_name, commit, commit_number):
   """
   Generates the diffs for the commits of a repository.

   :param repository_name: Name of the repository to be analyzed.
   :param commit: The commit object to be analyzed.
   :param commit_number: Number of the commit to be analyzed.
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Generating the diffs for the {BackgroundColors.CYAN}{commit_number}ยบ{BackgroundColors.GREEN} commit of the {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} repository...{Style.RESET_ALL}")

   for modified_file in commit.modified_files: # Loop through the modified files of the commit
      file_diff = modified_file.diff # Get the diff of the modified file

      diff_file_directory = f"{START_PATH}{RELATIVE_DIFFS_DIRECTORY_PATH}/{repository_name}/{commit_number}-{commit.hash}/" # Define the directory to save the diff file

      if not verify_filepath_exists(diff_file_directory): # Verify if the directory does not exist
         os.makedirs(diff_file_directory, exist_ok=True) # Create the directory

      # Open the diff file to write the diff
      with open(f"{diff_file_directory}{modified_file.filename}{DIFF_FILE_EXTENSION}", "w", encoding="utf-8", errors="ignore") as diff_file:
         diff_file.write(file_diff) # Write the diff to the file

def checkout_branch(branch_name):
   """
   Checks out a specific branch.

   :param branch_name: Name of the branch to be checked out.
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Checking out the {BackgroundColors.CYAN}{branch_name}{BackgroundColors.GREEN} branch...{Style.RESET_ALL}")

   checkout_thread = subprocess.Popen(["git", "checkout", branch_name], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # Run the Git command to checkout the branch
   checkout_thread.wait() # Wait for the thread to finish

def generate_output_directory_paths(repository_name, commit_number, commit_hash):
   """
   Generates the output directory path for the CK metrics generator.

   :param repository_name: Name of the repository to be analyzed.
   :param commit_number: Number of the commit to be analyzed.
   :param commit_hash: Commit hash of the commit to be analyzed.
   :return: The output_directory and relative_output_directory paths.
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Generating the output directory paths...{Style.RESET_ALL}")

   output_directory = f"{FULL_CK_METRICS_DIRECTORY_PATH}/{repository_name}/{commit_number}-{commit_hash}/" # Define the output directory path
   relative_output_directory = f"{RELATIVE_CK_METRICS_DIRECTORY_PATH}/{repository_name}/{commit_number}-{commit_hash}/" # Define the relative output directory path

   return output_directory, relative_output_directory # Return the output_directory and relative_output_directory paths
   
def run_ck_metrics_generator(cmd):
   """
   Runs the CK metrics generator in a subprocess.

   :param cmd: Command to be executed.
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Running the CK Metrics Generator Command...{Style.RESET_ALL}")

   thread = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE) # Run the CK metrics generator command
   stdout, stderr = thread.communicate() # Get the stdout and stderr of the thread

def get_class_and_loc_metrics(output_directory):
   """
   Extracts the number of classes and lines of code from the CK output files.

   :param output_directory: Path to the directory containing the CK metrics files.
   :return: Tuple (classes, lines_of_code).
   """

   class_count = 0 # Total number of classes
   loc_count = 0 # Total number of lines of code

   with open(f"{output_directory}/class.csv", "r") as file: # Open the CK metrics CSV file to extract the metrics
      reader = csv.DictReader(file) # Read the CSV file
      for row in reader: # Loop through the rows of the CSV file
         class_count += 1 # Increment the class count
         loc_count += int(row["loc"]) # Increment the lines of code count

   return class_count, loc_count # Return the class count and lines of code count

def sum_directory_files_size(directory):
   """
   Calculates the total size of the given directory in bytes.

   :param directory: Path to the directory.
   :return: Total size of the directory in bytes.
   """

   total_size = 0 # Total size of the directory
   for dirpath, dirnames, filenames in os.walk(directory): # Walk through the directory
      for filename in filenames: # Loop through the filenames
         filepath = os.path.join(dirpath, filename) # Join the directory path with the filename
         total_size += os.path.getsize(filepath) # Get the size of the file and add it to the total size
   return total_size # Return the total size of the directory

def show_execution_time(first_iteration_duration, elapsed_time, number_of_commits, repository_name):
   """
   Shows the execution time of the CK metrics generator.

   :param first_iteration_duration: Duration of the first iteration.
   :param elapsed_time: Elapsed time of the execution.
   :param number_of_commits: Number of commits to be analyzed.
   :param repository_name: Name of the repository to be analyzed.
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Showing the execution time of the CK metrics generator...{Style.RESET_ALL}")

   estimated_time_string = f"{BackgroundColors.GREEN}Estimated time for running all the of the iterations in {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN}: "
   output_time(estimated_time_string, round(first_iteration_duration * number_of_commits, 2)) # Output the estimated time for running all of the iterations for the repository
   time_taken_string = f"{BackgroundColors.GREEN}Time taken to generate CK metrics for {BackgroundColors.CYAN}{number_of_commits}{BackgroundColors.GREEN} commits in {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} repository: "
   output_time(time_taken_string, round(elapsed_time, 2)) # Output the time taken to generate CK metrics for the commits in the repository

def get_filtered_sorted_directories(directory_path):
   """
   Get and sort directories by the commit number.

   :param directory_path: Path to the directory containing subdirectories
   :return: List of sorted directories by commit number
   """

   dirnames = os.listdir(directory_path) # Get the directory names
   filtered_dirs = [dirname for dirname in dirnames if "-" in dirname and dirname.split("-")[0].isdigit()] # Filter directories
   return sorted(filtered_dirs, key=lambda dirname: int(dirname.split("-")[0])) # Sort by commit number

def get_last_directory(dirs):
   """
   Get the last directory from a sorted list of directories.

   :param dirs: List of sorted directories
   :return: Last directory in the list
   """

   return dirs[-1] if dirs else "" # Return the last directory if the list is not empty

def get_directory_size_in_gb(directory_path):
   """
   Get the size of a directory in GB.

   :param directory_path: Path to the directory
   :return: Size of the directory in GB
   """

   return sum_directory_files_size(directory_path) / (1024 ** 3) # Size in GB

def get_output_directories_size_in_gb(repository_name, output_directories=OUTPUT_DIRECTORIES):
   """
   Get the size of the output directories in GB.

   :param repository_name: Name of the repository.
   :return: Total size of the output directories in GB
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Getting the size of the output directories in {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} repository...{Style.RESET_ALL}")

   output_dirs_size = 0 # Total size of the output directories in GB
   for output_dir in output_directories: # Loop through the output directories
      output_dirs_size += get_directory_size_in_gb(os.path.join(output_dir, output_dir)) # Get the size of each output directory in GB
   
   return output_dirs_size # Return the total size of the output directories in GB

def get_file_size_in_gb(filepath):
   """
   Returns the size of the file in GB.
   If the file does not exist, the size is 0 GB.

   :param filepath: Path to the file
   :return: float, size of the progress file in GB
   """

   try: # Try to get the size of the progress file
      file_size = os.path.getsize(filepath) / (1024 ** 3) # Size in GB
   except FileNotFoundError:
      file_size = 0 # File does not exist, size is 0 GB
   return file_size # Return the size of the progress file in GB

def get_repository_attributes(repository_name, number_of_commits, elapsed_time):
   """
   Retrieves repository attributes such as the number of classes, lines of code, and directory sizes.

   :param repository_name: Name of the repository.
   :param number_of_commits: Number of commits to be analyzed.
   :param elapsed_time: Elapsed time of the execution.
   :return: A dictionary with repository attributes.
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Retrieving the repository attributes...{Style.RESET_ALL}")

   output_directory = os.path.join(FULL_CK_METRICS_DIRECTORY_PATH, repository_name) # The path to the CK metrics directory
   sorted_dirs = get_filtered_sorted_directories(output_directory) # Get and sort directories

   last_directory = get_last_directory(sorted_dirs) # Get the last directory
   last_directory_path = os.path.join(output_directory, last_directory) # Update the output directory with the last directory

   total_classes, total_lines_of_code = get_class_and_loc_metrics(last_directory_path) # Get the total number of classes and lines of code

   # Get the size of the output directories in GB and the progress file size in GB
   output_dirs_size = get_output_directories_size_in_gb(repository_name, OUTPUT_DIRECTORIES) + get_file_size_in_gb(FULL_REPOSITORY_PROGRESS_FILE_PATH.replace("repository_name", repository_name))

   return { # Return the repository attributes dictionary
      "repository_name": repository_name, # Name of the repository
      "classes": total_classes, # Total number of classes
      "lines_of_code": total_lines_of_code, # Total number of lines of code
      "commits": number_of_commits, # Total number of commits
      "execution_time_in_minutes": round(elapsed_time / 60, 2), # Execution time in minutes
      "size_in_gb": round(output_dirs_size, 2) # Size of the output directories in GB
   }

def traverse_repository(repository_name, repository_url, number_of_commits):
   """
   Traverses the repository to run CK for every commit hash in the repository.
   Tracks the processing time, number of classes, lines of code, and other attributes.

   :param repository_name: Name of the repository to be analyzed.
   :param repository_url: URL of the repository to be analyzed.
   :param number_of_commits: Number of commits to be analyzed.
   :return: A tuple with the commits information list and a dictionary with repository attributes.
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Traversing the {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} repository to run CK for every commit hash...{Style.RESET_ALL}")

   start_time = time.time() # Start measuring time
   first_iteration_duration = 0 # Duration of the first iteration
   commit_number = 1 # The current commit number
   saved_progress_file = FULL_REPOSITORY_PROGRESS_FILE_PATH.replace("repository_name", repository_name) # The path to the saved progress file

   commits_info, last_commit_number = get_last_execution_progress(repository_name, saved_progress_file, number_of_commits) # Get the last execution progress of the repository

   # Create a progress bar with the total number of commits
   with tqdm(total=number_of_commits - last_commit_number, unit=f"{BackgroundColors.GREEN}Traversing the {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} commit tree{Style.RESET_ALL}", unit_scale=True) as pbar:
      for commit in Repository(repository_url).traverse_commits(): # Loop through the commits of the repository
         if commit_number < last_commit_number: # If the current commit number is less than the last commit number
            commit_number += 1 # Increment the commit number
            pbar.update(1) # Update the progress bar
            continue # Jump to the next iteration

         lines_added, lines_removed = sum(file.added_lines for file in commit.modified_files), sum(file.deleted_lines for file in commit.modified_files) # Lines added and removed
         code_churn = lines_added - lines_removed # Code churn
         modified_files_count = len(commit.modified_files) # Number of modified files
         code_churn_avg_per_file = code_churn / modified_files_count if modified_files_count > 0 else 0 # Code churn average per file

         current_tuple = (commit_number, commit.hash, commit.msg.replace("\n", " // "), commit.committer_date, lines_added, lines_removed, code_churn, code_churn_avg_per_file, modified_files_count, f"{repository_url}/commit/{commit.hash}") # Create a tuple with the commit information
         commits_info.append(current_tuple) # Append the current tuple to the commits_info list

         generate_diffs(repository_name, commit, commit_number) if RUN_FUNCTIONS["generate_diffs"] else None # Save the diff of the modified files of the current commit

         workdir = f"{FULL_REPOSITORIES_DIRECTORY_PATH}/{repository_name}" # The path to the repository directory
         os.chdir(workdir) # Change working directory to the repository directory

         checkout_branch(commit.hash) # Checkout the current commit hash branch to run ck

         output_directory, relative_output_directory = generate_output_directory_paths(repository_name, commit_number, commit.hash) # Generate the output directory paths
         create_directory(output_directory, relative_output_directory) # Create the ck_metrics directory

         os.chdir(output_directory) # Change working directory to the repository directory

         cmd = f"java -jar {FULL_CK_JAR_PATH} {workdir} false 0 false {output_directory} true" # The command to run the CK metrics generator
         run_ck_metrics_generator(cmd) # Run the CK metrics generator

         if commit_number == 1: # If it is the first iteration
            first_iteration_duration = time.time() - start_time # Calculate the duration of the first iteration

         with open(saved_progress_file, "a") as progress_file: # Open the progress file to append
            progress_file.write(f",".join(map(str, current_tuple)) + "\n") # Write the current tuple to the progress file
         commit_number += 1 # Increment the commit number
         pbar.update(1) # Update the progress bar

   os.remove(saved_progress_file) # Remove the saved progress file when processing is complete

   elapsed_time = time.time() - start_time # Calculate elapsed time
   show_execution_time(first_iteration_duration, elapsed_time, number_of_commits, repository_name) # Show the execution time of the CK metrics generator

   return commits_info, get_repository_attributes(repository_name, number_of_commits, elapsed_time) # Return the commits info and repository attributes

def write_commits_information_to_csv(repository_name, commit_info):
   """
   Writes the commit information to a csv file.

   :param repository_name: Name of the repository to be analyzed.
   :param commit_info: List of tuples containing the commit hashes, commit messages and commit dates.
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Writing the commit information to a csv file...{Style.RESET_ALL}")
   
   file_path = f"{FULL_CK_METRICS_DIRECTORY_PATH}/{repository_name}-commits_list{CSV_FILE_EXTENSION}" # The path to the CSV file
   with open(file_path, "w", newline="") as csv_file: # Open the file in write mode
      writer = csv.writer(csv_file) # Create a csv writer
      writer.writerow(["Commit Number", "Commit Hash", "Commit Message", "Commit Date", "Lines Added", "Lines Removed", "Commit Code Churn", "Code Churn Avg Per File", "Modified Files Count"]) # Write the header
      writer.writerows(commit_info) # Write the commit hashes

def write_repositories_attributes_to_csv(repository_attributes):
   """
   Writes the repositories attributes to a csv file.

   :param repository_attributes: Dictionary containing the repositories attributes.
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Writing the repositories attributes to a csv file...{Style.RESET_ALL}")
   
   file_exists = verify_filepath_exists(FULL_REPOSITORIES_ATTRIBUTES_FILE_PATH) # Verify if the file already exists
   
   # Open the file in append mode if it exists, else in write mode
   with open(FULL_REPOSITORIES_ATTRIBUTES_FILE_PATH, "a" if file_exists else "w", newline="") as csv_file:
      writer = csv.writer(csv_file) # Create a csv writer
      
      if not file_exists: # If the file does not exist, write the header
         writer.writerow(["Repository Name", "Number of Classes", "Lines of Code (LOC)", "Number of Commits", "Execution Time (Minutes)", "Size (GB)"]) # Write the header
      
      # Write the repository attributes
      writer.writerow([
         repository_attributes["repository_name"], # Name of the repository
         repository_attributes["classes"], # Number of classes in the repository
         repository_attributes["lines_of_code"], # Number of lines of code in the repository
         repository_attributes["commits"], # Number of commits in the repository
         repository_attributes["execution_time_in_minutes"], # Execution time in minutes
         repository_attributes["size_in_gb"] # Size of the repository in GB
      ])

def process_repository(repository_name, repository_url):
   """
   Processes the repository.

   :param repository_name: Name of the repository to be analyzed.
   :param repository_url: URL of the repository to be analyzed.
   :return: None
   """

   print(f"{BackgroundColors.GREEN}Processing the {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} repository...{Style.RESET_ALL}")

   if verify_ck_metrics_folder(repository_name): # Verify if the metrics were already calculated
      print(f"{BackgroundColors.GREEN}The metrics for {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} were already calculated!{Style.RESET_ALL}")
      return # Return if the metrics were already calculated

   create_directory(FULL_CK_METRICS_DIRECTORY_PATH, RELATIVE_CK_METRICS_DIRECTORY_PATH) # Create the ck metrics directory
   create_directory(FULL_PROGRESS_DIRECTORY_PATH, RELATIVE_PROGRESS_DIRECTORY_PATH) # Create the progress directory
   create_directory(FULL_REPOSITORIES_DIRECTORY_PATH, RELATIVE_REPOSITORIES_DIRECTORY_PATH) # Create the repositories directory

   setup_repository(repository_name, repository_url) # Setup the repository: Clone or update the repository

   number_of_commits = count_commits(f"{FULL_REPOSITORIES_DIRECTORY_PATH}/{repository_name}") # Count the number of commits in the repository
   
   commits_info, repository_attributes = traverse_repository(repository_name, repository_url, number_of_commits) # Traverse the repository to run CK for every commit hash in the repository

   write_commits_information_to_csv(repository_name, commits_info) if RUN_FUNCTIONS["write_commits_information_to_csv"] else None # Write the commits information to a CSV file

   write_repositories_attributes_to_csv(repository_attributes) if RUN_FUNCTIONS["write_repositories_attributes_to_csv"] else None # Save repository attributes to a CSV file

   checkout_branch("main") # Checkout the main branch

def process_repositories_in_parallel():
   """
   Processes each repository in the DEFAULT_REPOSITORIES dictionary in parallel using a thread pool.

   :return: None
   """

   print(f"{BackgroundColors.GREEN}Processing each of the repositories in parallel using a Thread Pool...{Style.RESET_ALL}")

   cpu_cores = get_threads() # Get the number of CPU cores
   usable_threads, max_threads = get_adjusted_number_of_threads(cpu_cores) # Get the adjusted number of threads to use

   print(f"{BackgroundColors.GREEN}The number of usable threads is {BackgroundColors.CYAN}{usable_threads}{BackgroundColors.GREEN} out of {BackgroundColors.CYAN}{max_threads}{BackgroundColors.GREEN}.{Style.RESET_ALL}")

   def process_and_estimate(repository_name, repository_url): # Function to process each repository and estimate the time
      estimated_time_string = f"{BackgroundColors.GREEN}Estimated time for running all iterations for {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN}: "

      # Traverse commits in the repository and count them without materializing the entire list
      commits_number = sum(1 for _ in Repository(repository_url).traverse_commits()) # Efficient commit count
      estimated_time = round(((commits_number / 1000) * commits_number), 2) # Estimate the time to process the repository
      output_time(estimated_time_string, estimated_time) # Output the estimated time
      process_repository(repository_name, repository_url) # Process the repository

   # Use ThreadPoolExecutor with a limit of usable_threads
   with concurrent.futures.ThreadPoolExecutor(max_workers=usable_threads) as executor:
      futures = [ # Create a list of futures. Futures are used to manage the execution of the function in the thread pool
         executor.submit(process_and_estimate, repository_name, repository_url) # Submit the process_and_estimate function
         for repository_name, repository_url in DEFAULT_REPOSITORIES.items() # Loop through the DEFAULT_REPOSITORIES dictionary
      ]
      concurrent.futures.wait(futures) # Wait for all tasks to complete

# Register the function to play a sound when the program finishes
atexit.register(play_sound)

def main():
   """
   Main function.

   :return: None
   """

   start_time = datetime.now() # Get the start time
   
   if path_contains_whitespaces(): # Verify if the path constants contains whitespaces
      print(f"{BackgroundColors.RED}The {START_PATH} constant contains whitespaces. Please remove them!{Style.RESET_ALL}")
      return # Return if the path constants contains whitespaces

   global SOUND_FILE_PATH # Declare the SOUND_FILE_PATH as a global variable
   SOUND_FILE_PATH = update_sound_file_path() # Update the sound file path
   
   if not verify_git(): # Verify if Git is installed
      return # Return if Git is not installed
   
   if not ensure_ck_jar_file_exists(): # Verify and ensure that the CK JAR file exists
      return # Return if the CK JAR file does not exist

   verify_repositories_execution_constants() # Verify the DEFAULT_REPOSITORIES constant
   
   # Print the Welcome Messages
   print(f"{BackgroundColors.GREEN}Welcome to the {BackgroundColors.CYAN}CK Metrics Generator{BackgroundColors.GREEN}! This script is a key component of the {BackgroundColors.CYAN}Worked Example Miner (WEM) Project{BackgroundColors.GREEN}.{Style.RESET_ALL}")
   print(f"{BackgroundColors.GREEN}This script will process the repositories: {BackgroundColors.CYAN}{json.dumps(list(DEFAULT_REPOSITORIES.keys()))}{BackgroundColors.GREEN} in parallel using threads.{Style.RESET_ALL}")
   print(f"{BackgroundColors.GREEN}The files that this script will generate are the {BackgroundColors.CYAN}ck metrics files, the commit hashes list file and the diffs of each commit{BackgroundColors.GREEN}, in which are used by the {BackgroundColors.CYAN}Metrics Changes{BackgroundColors.GREEN} Python script.{Style.RESET_ALL}", end="\n\n")   

   process_repositories_in_parallel() # Process each of the repositories in parallel

   end_time = datetime.now() # Get the end time
   output_time(f"\n{BackgroundColors.GREEN}Total execution time: ", (end_time - start_time).total_seconds()) # Output the total execution time

   # Print the message that the CK metrics generator has finished processing the repositories
   print(f"\n{BackgroundColors.GREEN}The {BackgroundColors.CYAN}CK Metrics Generator{BackgroundColors.GREEN} has finished processing the repositories.{Style.RESET_ALL}", end="\n\n")
		
if __name__ == "__main__":
   """
   This is the standard boilerplate that calls the main() function.

   :return: None
   """

   main() # Call the main function
