import atexit # For playing a sound when the program finishes
import concurrent.futures # For running tasks in parallel
import csv # CSV (Comma Separated Values) is a simple file format used to store tabular data, such as a spreadsheet or database
import json # JSON (JavaScript Object Notation) is a lightweight data-interchange format
import os # OS module in Python provides functions for interacting with the operating system
import pandas as pd # Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool
import subprocess # The subprocess module allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes
import time # This module provides various time-related functions
from colorama import Style # For coloring the terminal
from pydriller import Repository # PyDriller is a Python framework that helps developers in analyzing Git repositories. 
from tqdm import tqdm # For Generating the Progress Bars

# Import from the repositories_picker.py file
from repositories_picker import BackgroundColors # For coloring the terminal outputs
from repositories_picker import JSON_FILE_EXTENSION, SOUND_FILE_PATH # For the sound file path
from repositories_picker import get_threads, play_sound, update_sound_file_path, verify_git # For updating the sound file path

# Default values that can be changed:
PROCESS_JSON_REPOSITORIES = True # Process the JSON repositories. If set to True, it will process the JSON repositories, otherwise it will pick the ones defined in the DEFAULT_REPOSITORIES dictionary.

DEFAULT_REPOSITORIES = { # The default repositories to be analyzed in the format: "repository_name": "repository_url"
   "CorfuDB": "https://github.com/CorfuDB/CorfuDB",
   "kafka": "https://github.com/apache/kafka",
   "moleculer-java": "https://github.com/moleculer-java/moleculer-java",
   "scalecube-services": "https://github.com/scalecube/scalecube-services",
   "zookeeper": "https://github.com/apache/zookeeper"
}

VERBOSE = False # Verbose mode. If set to True, it will output messages at the start/call of each function (Note: It will output a lot of messages).

# Default paths:
START_PATH = os.getcwd() # Get the current working directory

# File Extensions Constants:
CSV_FILE_EXTENSION = ".csv" # The extension of the file that contains the commit hashes
DIFF_FILE_EXTENSION = ".diff" # The diff file extension

# CK Constants:
CK_BRANCH = "FEAT-ClassMetric" # The branch of the CK repository to be used
CK_METRICS_FILES = ["class.csv", "method.csv"] # The files that are generated by CK

# Time units:
TIME_UNITS = [60, 3600, 86400] # Seconds in a minute, seconds in an hour, seconds in a day
 
# Relative paths:
RELATIVE_CK_SUBMODULE_PATH = "../ck" # The relative path of the CK submodule
RELATIVE_CK_JAR_PATH = f"{RELATIVE_CK_SUBMODULE_PATH}/target/ck-0.7.1-SNAPSHOT-jar-with-dependencies.jar" # The relative path of the CK JAR file
RELATIVE_CK_METRICS_DIRECTORY_PATH = "/ck_metrics" # The relative path of the directory that contains the CK generated files
RELATIVE_DIFFS_DIRECTORY_PATH = "/diffs" # The relative path of the directory that contains the diffs
RELATIVE_PROGRESS_DIRECTORY_PATH = "/progress" # The relative path of the progress file
RELATIVE_REFACTORINGS_DIRECTORY_PATH = "/refactorings" # The relative path of the directory that contains the refactorings
RELATIVE_REPOSITORIES_DIRECTORY_PATH = "/repositories" # The relative path of the directory that contains the repositories
RELATIVE_REPOSITORIES_ATTRIBUTES_FILE_PATH = f"{RELATIVE_REPOSITORIES_DIRECTORY_PATH}/repositories_attributes{CSV_FILE_EXTENSION}" # The relative path of the file that contains the repositories attributes
RELATIVE_REPOSITORY_PROGRESS_FILE_PATH = f"{RELATIVE_REPOSITORIES_DIRECTORY_PATH}/repository_name-progress{CSV_FILE_EXTENSION}" # The relative path of the file that contains the repository progress
RELATIVE_REPOSITORIES_LIST_FILE_PATH = f"{RELATIVE_REPOSITORIES_DIRECTORY_PATH}/repositories{JSON_FILE_EXTENSION}" # The relative path of the file that contains the repositories list

# Full paths (Start Path + Relative Paths):
FULL_CK_JAR_PATH = START_PATH.replace("PyDriller", "") + RELATIVE_CK_JAR_PATH.replace("../", "") # The full path of the CK JAR file
FULL_CK_METRICS_DIRECTORY_PATH = START_PATH + RELATIVE_CK_METRICS_DIRECTORY_PATH # The full path of the directory that contains the CK generated files
FULL_DIFFS_DIRECTORY_PATH = START_PATH + RELATIVE_DIFFS_DIRECTORY_PATH # The full path of the directory that contains the diffs
FULL_PROGRESS_DIRECTORY_PATH = START_PATH + RELATIVE_PROGRESS_DIRECTORY_PATH # The full path of the progress file
FULL_REFACTORINGS_DIRECTORY_PATH = START_PATH + RELATIVE_REFACTORINGS_DIRECTORY_PATH # The full path of the directory that contains the refactorings
FULL_REPOSITORIES_ATTRIBUTES_FILE_PATH = START_PATH + RELATIVE_REPOSITORIES_ATTRIBUTES_FILE_PATH # The full path of the file that contains the repositories attributes
FULL_REPOSITORIES_DIRECTORY_PATH = START_PATH + RELATIVE_REPOSITORIES_DIRECTORY_PATH # The full path of the directory that contains the repositories
FULL_REPOSITORY_PROGRESS_FILE_PATH = START_PATH + RELATIVE_REPOSITORY_PROGRESS_FILE_PATH # The full path of the file that contains the repository progress
FULL_REPOSITORIES_LIST_FILE_PATH = START_PATH + RELATIVE_REPOSITORIES_LIST_FILE_PATH # The full path of the file that contains the repositories list
OUTPUT_DIRECTORIES = [FULL_CK_METRICS_DIRECTORY_PATH, FULL_DIFFS_DIRECTORY_PATH, FULL_REPOSITORIES_DIRECTORY_PATH] # The list of output directories

def verbose_output(true_string="", false_string=""):
   """
   Outputs a message if the VERBOSE constant is set to True.

   :param true_string: The string to be outputted if the VERBOSE constant is set to True.
   :param false_string: The string to be outputted if the VERBOSE constant is set to False.
   :return: None
   """

   if VERBOSE and true_string != "": # If the VERBOSE constant is set to True and the true_string is set
      print(true_string) # Output the true statement string
   elif false_string != "":
      print(false_string) # Output the false statement string

def path_contains_whitespaces():
   """
   Verifies if the PATH constant contains whitespaces.

   :return: True if the PATH constant contains whitespaces, False otherwise.
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Verifying if the {BackgroundColors.CYAN}PATH{BackgroundColors.GREEN} constant contains whitespaces...{Style.RESET_ALL}")
   
   # Verify if the PATH constant contains whitespaces
   if " " in START_PATH: # If the PATH constant contains whitespaces
      return True # Return True if the PATH constant contains whitespaces
   return False # Return False if the PATH constant does not contain whitespaces

def init_and_update_submodules():
   """
   Initialize and update Git submodules

   :return: True if the Git submodules were initialized and updated successfully, False otherwise.
   """

   try:
      verbose_output(true_string=f"{BackgroundColors.GREEN}Initializing and updating the CK Git Submodule...{Style.RESET_ALL}")

      # Adjust path as necessary for reliability across environments
      submodule_path = os.path.abspath(f"{RELATIVE_CK_SUBMODULE_PATH}/.git") # Path to the ck submodule

      if not os.path.exists(submodule_path):
         subprocess.run(["git", "submodule", "init"], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
         subprocess.run(["git", "submodule", "update"], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
      else:
         subprocess.run(["git", "submodule", "update", "--remote"], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
   except subprocess.CalledProcessError as e:
      print(f"{BackgroundColors.RED}An error occurred while initializing and updating the CK Git Submodule: {e}{Style.RESET_ALL}")
      return False # Return False if the Git submodules could not be initialized and updated
   return True # Return True if the Git submodules were initialized and updated successfully

def get_current_branch(repo_path):
   """
   Retrieve the current branch of the repository at the specified path.
   
   :param repo_path: Path to the repository
   :return: The name of the current branch
   """

   result = subprocess.run(["git", "rev-parse", "--abbrev-ref", "HEAD"], cwd=repo_path, capture_output=True, text=True)
   return result.stdout.strip() # Get the current branch

def switch_branch(target_branch, repo_path):
   """
   Switch branches in the specified repository.
   
   :param target_branch: The name of the target branch
   :param repo_path: Path to the repository
   :return: True if the branch was successfully switched, False otherwise
   """
   
   try:
      subprocess.run(["git", "checkout", target_branch], cwd=repo_path, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
      verbose_output(true_string=f"{BackgroundColors.GREEN}Successfully switched to {BackgroundColors.CYAN}{target_branch}{BackgroundColors.GREEN} branch.{Style.RESET_ALL}")
      return True
   except subprocess.CalledProcessError:
      print(f"{BackgroundColors.RED}Failed to switch to {BackgroundColors.GREEN}{target_branch}{BackgroundColors.RED} branch.{Style.RESET_ALL}")
      return False

def build_ck_jar_file(repo_path):
   """
   Build the CK JAR file if it doesn't already exist.
   
   :param repo_path: Path to the ck submodule
   :return: True if the JAR file was successfully built, False otherwise
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Building the CK JAR file...{Style.RESET_ALL}")
   subprocess.run(["mvn", "clean", "package", "-DskipTests"], cwd=repo_path, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
   return os.path.exists(RELATIVE_CK_JAR_PATH) # Return True if the JAR file exists, False otherwise

def ensure_ck_jar_file_exists():
   """
   Ensure that the CK JAR file exists in the ck directory. If not, build the CK JAR file.
   We don't verify if the CK_JAR already exists in the target directory because we want to ensure that the latest version is used.
   
   :return: True if the CK JAR file was found or built successfully, False otherwise.
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Ensuring that the {BackgroundColors.CYAN}CK JAR{BackgroundColors.GREEN} file exists in the target directory...{Style.RESET_ALL}")

   # Initialize and update Git submodules
   if not init_and_update_submodules():
      return False # Return if the Git submodules could not be initialized and updated

   ck_repo_path = os.path.abspath(RELATIVE_CK_SUBMODULE_PATH) # Path to the ck submodule

   # Store the current branch before switching
   original_branch = get_current_branch(ck_repo_path)

   # Try to switch to the desired CK branch if it exists
   if not switch_branch(CK_BRANCH, ck_repo_path):
      # If switching to CK_BRANCH fails, try to switch to a standard branch
      standard_branches = ["master", "main"]
      for branch in standard_branches:
         if switch_branch(branch, ck_repo_path):
            original_branch = branch # Successfully switched to a standard branch, use that as the fallback
            break # Exit the loop if a standard branch was found
      else:
         print(f"{BackgroundColors.RED}None of the standard branches {BackgroundColors.CYAN}{', '.join(standard_branches)}{BackgroundColors.RED} exist in {BackgroundColors.CYAN}'ck'{BackgroundColors.RED}. Please verify the repository structure.{Style.RESET_ALL}")
         return False # Return False if no valid branch was found

   # Build the JAR file if it does not exist
   if build_ck_jar_file(ck_repo_path):
      # Switch back to the original branch
      switch_branch(original_branch, ck_repo_path)
      # Verify if the jar exists in the ck directory
      if os.path.exists(RELATIVE_CK_JAR_PATH):
         return True # Return True if the CK JAR file was found in the target directory

   print(f"{BackgroundColors.RED}The {BackgroundColors.CYAN}CK JAR{BackgroundColors.RED} file was not found in the target directory.{Style.RESET_ALL}")
   return False # Return False if the JAR file was not found in the target directory

def verify_json_file(file_path):
   """
   Verify if the JSON file exists and is not empty.

   :param file_path: The path to the JSON file.
   :return: True if the JSON file exists and is not empty, False otherwise.
   """

   if not os.path.exists(file_path):
      print(f"{BackgroundColors.RED}The repositories JSON file does not exist.{Style.RESET_ALL}")
      return False # Return False if the JSON file does not exist
   if os.path.getsize(file_path) == 0:
      print(f"{BackgroundColors.RED}The repositories JSON file is empty.{Style.RESET_ALL}")
      return False # Return False if the JSON file is empty
   return True # Return True if the JSON file exists and is not empty

# Function to load repositories from JSON
def load_repositories_from_json(file_path):
   """
   Load repositories from a JSON file.

   :param file_path: The path to the JSON file.
   :return: A dictionary containing the repositories if the JSON file is valid, None otherwise.   
   """

   try:
      with open(file_path, "r", encoding="utf-8") as json_file: # Open the JSON file
         repositories_list = json.load(json_file) # Load the JSON file

      # Ensure the data is a list and contains repositories
      if isinstance(repositories_list, list) and repositories_list:
         return {repo["name"]: repo["url"] for repo in repositories_list} # Return the dictionary containing the repositories
      else:
         print(f"{BackgroundColors.RED}The repositories JSON file is not in the correct format.{Style.RESET_ALL}")
         return None # Return None if the JSON file is not in the correct format
   except (json.JSONDecodeError, KeyError) as e:
      verbose_output(true_string=f"{BackgroundColors.RED}Error parsing the repositories JSON file: {e}{Style.RESET_ALL}", is_error=True)
      return None # Return None if there is an error parsing the JSON file

def update_repositories_list():
   """
   Update the repositories list file with the DEFAULT_REPOSITORIES dictionary.
   
   :return: True if the DEFAULT_REPOSITORIES dictionary was successfully updated with values from the JSON file, False otherwise.
   """
   
   verbose_output(true_string=f"{BackgroundColors.GREEN}Updating the repositories list file with the DEFAULT_REPOSITORIES dictionary...{Style.RESET_ALL}")

   global DEFAULT_REPOSITORIES # Use the global DEFAULT_REPOSITORIES variable

   # Validate the JSON file
   if not verify_json_file(FULL_REPOSITORIES_LIST_FILE_PATH):
      return False # Return if the JSON file is not valid

   # Load repositories from JSON and update DEFAULT_REPOSITORIES
   json_repositories = load_repositories_from_json(FULL_REPOSITORIES_LIST_FILE_PATH)

   if not json_repositories: # If the JSON file was not successfully loaded
      return False # Return False if the DEFAULT_REPOSITORIES dictionary was not successfully updated with values from the JSON file

   DEFAULT_REPOSITORIES = json_repositories # Update the DEFAULT_REPOSITORIES dictionary with the values from the JSON file

   verbose_output(true_string=f"{BackgroundColors.GREEN}The {BackgroundColors.CLEAR_TERMINAL}DEFAULT_REPOSITORIES{BackgroundColors.GREEN} dictionary was successfully updated with values from the {BackgroundColors.CYAN}JSON{BackgroundColors.GREEN} file.{Style.RESET_ALL}")
   
   return True # Return True if the DEFAULT_REPOSITORIES dictionary was successfully updated with values from the JSON file

def verify_repositories_execution_constants():
   """
   Verify the constants used in the execution of the repositories.
   It will process the JSON repositories, if the PROCESS_JSON_REPOSITORIES constant is set to True or if the DEFAULT_REPOSITORIES dictionary is empty.
   
   :return: None
   """

   # Verify if PROCESS_REPOSITORIES_LIST is set to True or if the DEFAULT_REPOSITORIES dictionary is empty
   if PROCESS_JSON_REPOSITORIES or not DEFAULT_REPOSITORIES:
      if not update_repositories_list(): # Update the repositories list
         print(f"{BackgroundColors.RED}The repositories list could not be updated. Please execute the {BackgroundColors.CYAN}repositories_picker.py{BackgroundColors.RED} script or manually fill the {BackgroundColors.CYAN}DEFAULT_REPOSITORIES{BackgroundColors.RED} dictionary.{Style.RESET_ALL}")
         exit() # Exit the program if the repositories list could not be updated

def output_time(output_string, time):
   """
   Outputs time, considering the appropriate time unit.

   :param output_string: String to be outputted.
   :param time: Time to be outputted.
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Outputting the time in the most appropriate time unit...{Style.RESET_ALL}")

   if float(time) < int(TIME_UNITS[0]): # If the time is less than 60 seconds
      time_unit = "seconds" # Set the time unit to seconds
      time_value = time # Set the time value to time
   elif float(time) < float(TIME_UNITS[1]): # If the time is less than 3600 seconds
      time_unit = "minutes" # Set the time unit to minutes
      time_value = time / TIME_UNITS[0] # Set the time value to time divided by 60
   elif float(time) < float(TIME_UNITS[2]): # If the time is less than 86400 seconds
      time_unit = "hours" # Set the time unit to hours
      time_value = time / TIME_UNITS[1] # Set the time value to time divided by 3600
   else: # If the time is greater than or equal to 86400 seconds
      time_unit = "days" # Set the time unit to days
      time_value = time / TIME_UNITS[2] # Set the time value to time divided by 86400

   rounded_time = round(time_value, 2) # Round the time value to two decimal places
   print(f"{BackgroundColors.GREEN}{output_string}{BackgroundColors.CYAN}{rounded_time} {time_unit}{BackgroundColors.GREEN}.{Style.RESET_ALL}")

def get_commit_hashes(commit_file_path):
   """
   Read the commit hashes from a CSV file.

   :param commit_file_path: Path to the CSV file containing commit hashes
   :return: List of commit hashes
   """
   
   if not os.path.exists(commit_file_path):
      return [] # Return an empty list if the file does not exist

   # Read the commit hashes CSV file and get the commit_hashes column, ignoring the first line
   return pd.read_csv(commit_file_path, sep=",", usecols=["Commit Hash"], header=0).values.tolist()

def verify_folder_exists(folder_path):
   """
   Verify if a folder exists at the specified path.

   :param folder_path: Path to the folder
   :return: True if the folder exists, False otherwise
   """

   return os.path.exists(folder_path)

def verify_ck_metrics_files(folder_path, ck_metrics_files):
   """
   Verify if all the CK metrics files exist inside the specified folder.

   :param folder_path: Path to the folder containing CK metrics files
   :param ck_metrics_files: List of CK metrics file names to check
   :return: True if all CK metrics files exist, False otherwise
   """

   for ck_metric_file in ck_metrics_files: # Loop through the CK metrics files
      ck_metric_file_path = os.path.join(folder_path, ck_metric_file) # Join the folder path with the CK metric file
      if not os.path.exists(ck_metric_file_path): # If the CK metric file does not exist
         return False # Return False if the CK metric file does not exist
   return True # Return True if all CK metrics files exist

def verify_ck_metrics_folder(repository_name):
   """
   Verifies if all the metrics are already calculated by opening the commit hashes file and checking if every commit hash in the file is a folder in the repository folder.

   :param repository_name: Name of the repository to be analyzed.
   :return: True if all the metrics are already calculated, False otherwise.
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Verifying if the metrics for {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} were already calculated...{Style.RESET_ALL}")

   data_path = os.path.join(START_PATH, RELATIVE_CK_METRICS_DIRECTORY_PATH[1:]) # Join the PATH with the relative path of the ck metrics directory
   repo_path = os.path.join(data_path, repository_name) # Join the data path with the repository name
   commit_file = f"{repository_name}-commits_list{CSV_FILE_EXTENSION}" # The name of the commit hashes file
   commit_file_path = os.path.join(data_path, commit_file) # Join the data path with the commit hashes file

   commit_hashes = get_commit_hashes(commit_file_path) # Get the commit hashes

   if not commit_hashes:
      return False # Return False if the commit hashes list is empty

   for commit_hash in commit_hashes: # Loop through the commit hashes
      commit_file_filename = commit_hash[0] # This removes the brackets from the commit hash
      folder_path = os.path.join(repo_path, commit_file_filename) # Join the repository path with the commit hash folder

      if verify_folder_exists(folder_path): # Verify if the folder exists
         if not verify_ck_metrics_files(folder_path, CK_METRICS_FILES): # Verify if all the CK metrics files exist
            return False # If any CK metrics file does not exist, return False
      else:
         return False # Return False if the folder does not exist

   return True # Return True if all the metrics are already calculated

def create_directory(full_directory_name, relative_directory_name):
   """
   Creates a directory.

   :param full_directory_name: Name of the directory to be created.
   :param relative_directory_name: Relative name of the directory to be created that will be shown in the terminal.
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Creating the {BackgroundColors.CYAN}{relative_directory_name}{BackgroundColors.GREEN} directory...{Style.RESET_ALL}")

   if os.path.isdir(full_directory_name): # Verify if the directory already exists
      return # Return if the directory already exists
   try: # Try to create the directory
      os.makedirs(full_directory_name) # Create the directory
   except OSError: # If the directory cannot be created
      print(f"{BackgroundColors.GREEN}The creation of the {BackgroundColors.CYAN}{relative_directory_name}{BackgroundColors.GREEN} directory failed.{Style.RESET_ALL}")

def update_repository(repository_directory_path):
   """
   Update the repository using "git pull".

   :param repository_directory_path: The path to the repository directory
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Updating the {BackgroundColors.CYAN}{repository_directory_path.split('/')[-1]}{BackgroundColors.GREEN} repository...{Style.RESET_ALL}")
   
   os.chdir(repository_directory_path) # Change the current working directory to the repository directory
   
   # Create a thread to update the repository located in RELATIVE_REPOSITORY_DIRECTORY + "/" + repository_name
   update_thread = subprocess.Popen(["git", "pull"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
   update_thread.wait() # Wait for the thread to finish
   os.chdir(START_PATH) # Change the current working directory to the default one

def clone_repository(repository_directory_path, repository_url):
   """
   Clone the repository to the repository directory.

   :param repository_directory_path: The path to the repository directory
   :param repository_url: URL of the repository to be analyzed
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Cloning the {BackgroundColors.CYAN}{repository_directory_path.split('/')[-1]}{BackgroundColors.GREEN} repository...{Style.RESET_ALL}")
   
   # Create a thread to clone the repository
   thread = subprocess.Popen(["git", "clone", repository_url, repository_directory_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
   # Wait for the thread to finish
   thread.wait()

def setup_repository(repository_name, repository_url):
   """"
   Setup the repository by cloning it or updating it if it already exists.

   :param repository_name: Name of the repository to be analyzed
   :param repository_url: URL of the repository to be analyzed
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Setting up the {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} repository...{Style.RESET_ALL}")
   
   repository_directory_path = f"{FULL_REPOSITORIES_DIRECTORY_PATH}/{repository_name}" # The path to the repository directory
   
   # Verify if the repository directory already exists and if it is not empty
   if os.path.isdir(repository_directory_path) and os.listdir(repository_directory_path):
      update_repository(repository_directory_path) # Update the repository
   else:
      clone_repository(repository_directory_path, repository_url) # Clone the repository

def read_progress_file(file_path):
   """
   Read the contents of the progress file, excluding the last two lines.

   :param file_path: Path to the saved progress file
   :return: List of lines from the progress file, excluding the last two lines
   """

   if not os.path.exists(file_path): # Verify if the file exists
      return [] # Return an empty list if the file does not exist

   with open(file_path, "r") as file: # Open the progress file
      lines = file.readlines() # Read the lines from the file
   
   return lines[:-2] # Remove the last two lines

def parse_commit_info(lines):
   """
   Parse commit information from the lines of the progress file.

   :param lines: List of lines from the progress file
   :return: Tuple containing the list of commit info and the last commit number
   """

   commits_info = [] # List to store the commit information
   last_commit_number = 0 # Variable to store the last commit number
   
   if len(lines) > 3: # If there are more than 3 lines in the file
      last_commit_number = int(lines[-1].split(",")[0]) # Get the last commit number from the last line
      for line in lines[1:]: # Loop through the lines, excluding the header
         parts = line.split(",") # Split the line by commas
         commit_info = (parts[1], parts[2], parts[3]) # Get the commit hash, commit message, and commit date
         commits_info.append(commit_info) # Append the commit information to the list
   
   return commits_info, last_commit_number # Return the list of commit information and the last commit number

def calculate_percentage_progress(last_commit_number, total_commits):
   """
   Calculate the percentage progress based on the last commit number.

   :param last_commit_number: The last processed commit number
   :param total_commits: Total number of commits to be processed
   :return: Percentage of progress as a rounded float
   """

   return round((last_commit_number / total_commits) * 100, 2) # Calculate the percentage progress

def write_progress_file(file_path, lines):
   """
   Write the provided lines to the progress file, including the header.

   :param file_path: Path to the saved progress file
   :param lines: List of lines to be written to the file
   """

   with open(file_path, "w") as file: # Open the progress file to write
      file.write("Commit Number,Commit Hash,Commit Message,Commit Date\n") # Write the header to the file
      for line in lines: # Loop through the lines
         file.write(line) # Write the line to the file

def get_last_execution_progress(repository_name, saved_progress_file, number_of_commits):
   """
   Gets the last execution progress of the repository.

   :param repository_name: Name of the repository to be analyzed.
   :param saved_progress_file: Name of the file that contains the saved progress.
   :param number_of_commits: Number of commits to be analyzed.
   :return: The commits_info and last_commit_number.
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Getting the last execution progress of the {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} repository...{Style.RESET_ALL}")

   lines = read_progress_file(saved_progress_file) # Read the progress file

   if lines: # If there are lines in the progress file
      commits_info, last_commit_number = parse_commit_info(lines) # Parse the commit information
      percentage_progress = calculate_percentage_progress(last_commit_number, number_of_commits) # Calculate the percentage progress
      
      last_commit_hash = commits_info[-1][0] if commits_info else "N/A" # Get the last commit hash
      
      print(f"{BackgroundColors.GREEN}{BackgroundColors.CYAN}{repository_name.capitalize()}{BackgroundColors.GREEN} stopped executing in {BackgroundColors.CYAN}{percentage_progress}%{BackgroundColors.GREEN} of its progress in the {BackgroundColors.CYAN}{last_commit_number}ยบ{BackgroundColors.GREEN} commit: {BackgroundColors.CYAN}{last_commit_hash}{BackgroundColors.GREEN}.{Style.RESET_ALL}")
      
      execution_time = f"{BackgroundColors.GREEN}Estimated time for running the remaining iterations in {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN}: {Style.RESET_ALL}"
      output_time(execution_time, number_of_commits - last_commit_number)

      write_progress_file(saved_progress_file, lines) # Update progress file without the last two lines
   else:
      # If there is no saved progress file, create one and write the header
      write_progress_file(saved_progress_file, [])
      commits_info = [] # Initialize the commits_info list
      last_commit_number = 0 # Initialize the last_commit_number variable

   return commits_info, last_commit_number # Return the commits_info and last_commit_number

def generate_diffs(repository_name, commit, commit_number):
   """
   Generates the diffs for the commits of a repository.

   :param repository_name: Name of the repository to be analyzed.
   :param commit: The commit object to be analyzed.
   :param commit_number: Number of the commit to be analyzed.
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Generating the diffs for the {BackgroundColors.CYAN}{commit_number}ยบ{BackgroundColors.GREEN} commit of the {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} repository...{Style.RESET_ALL}")

   for modified_file in commit.modified_files: # Loop through the modified files of the commit
      file_diff = modified_file.diff # Get the diff of the modified file

      diff_file_directory = f"{START_PATH}{RELATIVE_DIFFS_DIRECTORY_PATH}/{repository_name}/{commit_number}-{commit.hash}/" # Define the directory to save the diff file

      # Validate if the directory exists, if not, create it
      if not os.path.exists(diff_file_directory):
         os.makedirs(diff_file_directory, exist_ok=True) # Create the directory]

      # Open the diff file to write the diff
      with open(f"{diff_file_directory}{modified_file.filename}{DIFF_FILE_EXTENSION}", "w", encoding="utf-8", errors="ignore") as diff_file:
         diff_file.write(file_diff) # Write the diff to the file

def checkout_branch(branch_name):
   """
   Checks out a specific branch.

   :param branch_name: Name of the branch to be checked out.
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Checking out the {BackgroundColors.CYAN}{branch_name}{BackgroundColors.GREEN} branch...{Style.RESET_ALL}")

   # Create a thread to checkout the branch
   checkout_thread = subprocess.Popen(["git", "checkout", branch_name], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
   checkout_thread.wait() # Wait for the thread to finish

def generate_output_directory_paths(repository_name, commit_hash, commit_number):
   """
   Generates the output directory path for the CK metrics generator.

   :param repository_name: Name of the repository to be analyzed.
   :param commit_hash: Commit hash of the commit to be analyzed.
   :param commit_number: Number of the commit to be analyzed.
   :return: The output_directory and relative_output_directory paths.
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Generating the output directory paths...{Style.RESET_ALL}")

   output_directory = f"{FULL_CK_METRICS_DIRECTORY_PATH}/{repository_name}/{commit_number}-{commit_hash}/"
   relative_output_directory = f"{RELATIVE_CK_METRICS_DIRECTORY_PATH}/{repository_name}/{commit_number}-{commit_hash}/"

   return output_directory, relative_output_directory # Return the output_directory and relative_output_directory paths
   
def run_ck_metrics_generator(cmd):
   """
   Runs the CK metrics generator in a subprocess.

   :param cmd: Command to be executed.
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Running the CK Metrics Generator Command...{Style.RESET_ALL}")

   # Create a thread to run the cmd command
   thread = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE) # Run the cmd command in a subprocess
   stdout, stderr = thread.communicate() # Get the stdout and stderr of the thread

def get_class_and_loc_metrics(output_directory):
   """
   Extracts the number of classes and lines of code from the CK output files.

   :param output_directory: Path to the directory containing the CK metrics files.
   :return: Tuple (classes, lines_of_code).
   """

   class_count = 0 # Total number of classes
   loc_count = 0 # Total number of lines of code

   # Open the CK metrics CSV file to extract the metrics
   with open(f"{output_directory}/class.csv", "r") as file:
      reader = csv.DictReader(file) # Read the CSV file
      for row in reader: # Loop through the rows of the CSV file
         class_count += 1 # Increment the class count
         loc_count += int(row["loc"]) # Increment the lines of code count

   return class_count, loc_count # Return the class count and lines of code count

def sum_directory_files_size(directory):
   """
   Calculates the total size of the given directory in bytes.

   :param directory: Path to the directory.
   :return: Total size of the directory in bytes.
   """

   total_size = 0 # Total size of the directory
   for dirpath, dirnames, filenames in os.walk(directory): # Walk through the directory
      for filename in filenames: # Loop through the filenames
         filepath = os.path.join(dirpath, filename) # Join the directory path with the filename
         total_size += os.path.getsize(filepath) # Get the size of the file and add it to the total size
   return total_size # Return the total size of the directory

def show_execution_time(first_iteration_duration, elapsed_time, number_of_commits, repository_name):
   """
   Shows the execution time of the CK metrics generator.

   :param first_iteration_duration: Duration of the first iteration.
   :param elapsed_time: Elapsed time of the execution.
   :param number_of_commits: Number of commits to be analyzed.
   :param repository_name: Name of the repository to be analyzed.
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Showing the execution time of the CK metrics generator...{Style.RESET_ALL}")

   estimated_time_string = f"{BackgroundColors.GREEN}Estimated time for running all the of the iterations in {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN}: "
   output_time(estimated_time_string, round(first_iteration_duration * number_of_commits, 2)) # Output the estimated time for running all of the iterations for the repository
   time_taken_string = f"{BackgroundColors.GREEN}Time taken to generate CK metrics for {BackgroundColors.CYAN}{number_of_commits}{BackgroundColors.GREEN} commits in {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} repository: "
   output_time(time_taken_string, round(elapsed_time, 2)) # Output the time taken to generate CK metrics for the commits in the repository

def get_filtered_sorted_directories(directory_path):
   """
   Get and sort directories by the commit number.

   :param directory_path: Path to the directory containing subdirectories
   :return: List of sorted directories by commit number
   """

   dirnames = os.listdir(directory_path) # Get the directory names
   filtered_dirs = [dirname for dirname in dirnames if "-" in dirname and dirname.split("-")[0].isdigit()] # Filter directories
   return sorted(filtered_dirs, key=lambda dirname: int(dirname.split("-")[0])) # Sort by commit number

def get_last_directory(dirs):
   """
   Get the last directory from a sorted list of directories.

   :param dirs: List of sorted directories
   :return: Last directory in the list
   """

   return dirs[-1] if dirs else "" # Return the last directory if the list is not empty

def get_directory_size_in_gb(directory_path):
   """
   Get the size of a directory in GB.

   :param directory_path: Path to the directory
   :return: Size of the directory in GB
   """

   return sum_directory_files_size(directory_path) / (1024 ** 3) # Size in GB

def get_output_directories_size_in_gb(repository_name, output_directories=OUTPUT_DIRECTORIES):
   """
   Get the size of the output directories in GB.

   :param repository_name: Name of the repository.
   :return: Total size of the output directories in GB
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Getting the size of the output directories in {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} repository...{Style.RESET_ALL}")

   output_dirs_size = 0 # Total size of the output directories in GB
   for output_dir in output_directories: # Loop through the output directories
      # Get the size of each output directory in GB
      output_dirs_size += get_directory_size_in_gb(os.path.join(output_dir, output_dir))
   
   return output_dirs_size # Return the total size of the output directories in GB

def get_file_size_in_gb(filepath):
   """
   Returns the size of the file in GB.
   If the file does not exist, the size is 0 GB.

   :param filepath: Path to the file
   :return: float, size of the progress file in GB
   """

   try: # Try to get the size of the progress file
      file_size = os.path.getsize(filepath) / (1024 ** 3) # Size in GB
   except FileNotFoundError:
      file_size = 0 # File does not exist, size is 0 GB
   return file_size # Return the size of the progress file in GB

def get_repository_attributes(repository_name, number_of_commits, elapsed_time):
   """
   Retrieves repository attributes such as the number of classes, lines of code, and directory sizes.

   :param repository_name: Name of the repository.
   :param number_of_commits: Number of commits to be analyzed.
   :param elapsed_time: Elapsed time of the execution.
   :return: A dictionary with repository attributes.
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Retrieving the repository attributes...{Style.RESET_ALL}")

   output_directory = os.path.join(FULL_CK_METRICS_DIRECTORY_PATH, repository_name) # The path to the CK metrics directory
   sorted_dirs = get_filtered_sorted_directories(output_directory) # Get and sort directories

   last_directory = get_last_directory(sorted_dirs) # Get the last directory
   last_directory_path = os.path.join(output_directory, last_directory) # Update the output directory with the last directory

   # Get the total number of classes and lines of code
   total_classes, total_lines_of_code = get_class_and_loc_metrics(last_directory_path)

   # Get the size of the output directories in GB and the progress file size in GB
   output_dirs_size = get_output_directories_size_in_gb(repository_name, OUTPUT_DIRECTORIES) + get_file_size_in_gb(FULL_REPOSITORY_PROGRESS_FILE_PATH.replace("repository_name", repository_name))

   repository_attributes = { # Create a dictionary with the repository attributes
      "repository_name": repository_name,
      "classes": total_classes,
      "lines_of_code": total_lines_of_code,
      "commits": number_of_commits,
      "execution_time_in_minutes": round(elapsed_time / 60, 2),
      "size_in_gb": round(output_dirs_size, 2)
   }

   return repository_attributes # Return the repository attributes

def traverse_repository(repository_name, repository_url, number_of_commits):
   """
   Traverses the repository to run CK for every commit hash in the repository.
   Tracks the processing time, number of classes, lines of code, and other attributes.

   :param repository_name: Name of the repository to be analyzed.
   :param repository_url: URL of the repository to be analyzed.
   :param number_of_commits: Number of commits to be analyzed.
   :return: A tuple with the commits information list and a dictionary with repository attributes.
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Traversing the {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} repository to run CK for every commit hash...{Style.RESET_ALL}")

   start_time = time.time() # Start measuring time
   first_iteration_duration = 0 # Duration of the first iteration
   commit_number = 1 # The current commit number
   saved_progress_file = FULL_REPOSITORY_PROGRESS_FILE_PATH.replace("repository_name", repository_name) # The path to the saved progress file

   # Get the last execution progress of the repository
   commits_info, last_commit = get_last_execution_progress(repository_name, saved_progress_file, number_of_commits)

   # Create a progress bar with the total number of commits
   with tqdm(total=number_of_commits - last_commit, unit=f"{BackgroundColors.GREEN}Traversing the {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} commit tree{Style.RESET_ALL}", unit_scale=True) as pbar:
      for commit in Repository(repository_url).traverse_commits(): # Loop through the commits of the repository
         if commit_number < last_commit: # If the current commit number is less than the last commit number
            commit_number += 1 # Increment the commit number
            pbar.update(1) # Update the progress bar
            continue # Jump to the next iteration

         # Store the commit hash, commit message and commit date in one line of the list, separated by commas
         current_tuple = (f"{commit_number}-{commit.hash}", commit.msg.split("\n")[0], commit.committer_date)
         commits_info.append(current_tuple) # Append the current tuple to the commits_info list

         # Save the diff of the modified files of the current commit
         generate_diffs(repository_name, commit, commit_number)

         workdir = f"{FULL_REPOSITORIES_DIRECTORY_PATH}/{repository_name}" # The path to the repository directory
         os.chdir(workdir) # Change working directory to the repository directory

         # Checkout the current commit hash branch to run ck
         checkout_branch(commit.hash)

         # Create the ck_metrics directory paths
         output_directory, relative_output_directory = generate_output_directory_paths(repository_name, commit.hash, commit_number)
         create_directory(output_directory, relative_output_directory) # Create the ck_metrics directory

         os.chdir(output_directory) # Change working directory to the repository directory

         # Run ck metrics for the current commit hash
         cmd = f"java -jar {FULL_CK_JAR_PATH} {workdir} false 0 false {output_directory} true"
         run_ck_metrics_generator(cmd) # Run the CK metrics generator

         if commit_number == 1: # If it is the first iteration
            first_iteration_duration = time.time() - start_time # Calculate the duration of the first iteration

         # Append the commit hash, commit message and commit date to the progress file
         with open(saved_progress_file, "a") as progress_file:
            progress_file.write(f"{commit_number},{commit.hash},{current_tuple[1]},{current_tuple[2]}\n")

         commit_number += 1 # Increment the commit number
         pbar.update(1) # Update the progress bar

   # Remove the saved progress file when processing is complete
   os.remove(saved_progress_file)

   # Show the execution time of the CK metrics generator
   elapsed_time = time.time() - start_time # Calculate elapsed time
   show_execution_time(first_iteration_duration, elapsed_time, number_of_commits, repository_name)

   return commits_info, get_repository_attributes(repository_name, number_of_commits, elapsed_time) # Return the commits info and repository attributes

def write_commits_information_to_csv(repository_name, commit_info):
   """
   Writes the commit information to a csv file.

   :param repository_name: Name of the repository to be analyzed.
   :param commit_info: List of tuples containing the commit hashes, commit messages and commit dates.
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Writing the commit information to a csv file...{Style.RESET_ALL}")
   
   file_path = f"{FULL_CK_METRICS_DIRECTORY_PATH}/{repository_name}-commits_list{CSV_FILE_EXTENSION}"
   with open(file_path, "w", newline="") as csv_file:
      writer = csv.writer(csv_file) # Create a csv writer
      writer.writerow(["Commit Hash", "Commit Message", "Commit Date"]) # Write the header
      writer.writerows(commit_info) # Write the commit hashes

def write_repositories_attributes_to_csv(repository_attributes):
   """
   Writes the repositories attributes to a csv file.

   :param repository_attributes: Dictionary containing the repositories attributes.
   :return: None
   """

   verbose_output(true_string=f"{BackgroundColors.GREEN}Writing the repositories attributes to a csv file...{Style.RESET_ALL}")
   
   # Verify if the file already exists
   file_exists = os.path.exists(FULL_REPOSITORIES_ATTRIBUTES_FILE_PATH)
   
   # Open the file in append mode if it exists, else in write mode
   with open(FULL_REPOSITORIES_ATTRIBUTES_FILE_PATH, "a" if file_exists else "w", newline="") as csv_file:
      writer = csv.writer(csv_file) # Create a csv writer
      
      # If the file does not exist, write the header
      if not file_exists:
         writer.writerow(["Repository Name", "Number of Classes", "Lines of Code (LOC)", "Number of Commits", "Execution Time (Minutes)", "Size (GB)"])
      
      # Write the repository attributes
      writer.writerow([
         repository_attributes["repository_name"],
         repository_attributes["classes"],
         repository_attributes["lines_of_code"],
         repository_attributes["commits"],
         repository_attributes["execution_time_in_minutes"],
         repository_attributes["size_in_gb"]
      ])

def process_repository(repository_name, repository_url):
   """
   Processes the repository.

   :param repository_name: Name of the repository to be analyzed.
   :param repository_url: URL of the repository to be analyzed.
   :return: None
   """

   print(f"{BackgroundColors.GREEN}Processing the {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} repository...{Style.RESET_ALL}")

   # Verify if the metrics were already calculated
   if verify_ck_metrics_folder(repository_name):
      print(f"{BackgroundColors.GREEN}The metrics for {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN} were already calculated!{Style.RESET_ALL}")
      return

   # Create the ck metrics directory
   create_directory(FULL_CK_METRICS_DIRECTORY_PATH, RELATIVE_CK_METRICS_DIRECTORY_PATH)
   # Create the progress directory
   create_directory(FULL_PROGRESS_DIRECTORY_PATH, RELATIVE_PROGRESS_DIRECTORY_PATH)
   # Create the repositories directory
   create_directory(FULL_REPOSITORIES_DIRECTORY_PATH, RELATIVE_REPOSITORIES_DIRECTORY_PATH)

   # Setup the repository
   setup_repository(repository_name, repository_url)

   # Get the number of commits, which is needed to traverse the repository
   number_of_commits = len(list(Repository(repository_url).traverse_commits()))
   
   # Traverse the repository to run CK for every commit hash in the repository
   commits_info, repository_attributes = traverse_repository(repository_name, repository_url, number_of_commits)

   # Write the commits information to a CSV file
   write_commits_information_to_csv(repository_name, commits_info)
   
   # Save repository attributes to a CSV file
   write_repositories_attributes_to_csv(repository_attributes)

   # Checkout the main branch
   checkout_branch("main")

def get_adjusted_number_of_threads(cpu_count):
   """
   Get the adjusted number of threads to use based on the available CPU cores, following these rules:

   - Ensure at least 1 thread is used.
   - Always try leave at least 1 thread free.
   - If there are 8 or more cores, leave 2 threads free, so the system can still be usable in terms of cpu usage, but memory wise it will also be very high.
   """

   if cpu_count <= 2: # If there are 2 or fewer CPU cores
      usable_threads = 1 # Use 1 thread
   elif 3 <= cpu_count <= 7: # If there are between 3 and 7 CPU cores
      usable_threads = cpu_count - 1 # Leave 1 thread free
   else: # If there are 8 or more CPU cores
      usable_threads = cpu_count - 2 # Leave 2 threads free

   return max(1, usable_threads), cpu_count # Return the number of threads to use and the maximum number of threads available

def process_repositories_in_parallel():
   """
   Processes each repository in the DEFAULT_REPOSITORIES dictionary in parallel using a thread pool.

   :return: None
   """

   print(f"{BackgroundColors.GREEN}Processing each of the repositories in parallel using a Thread Pool...{Style.RESET_ALL}")

   cpu_cores = get_threads() # Get the number of CPU cores
   usable_threads, max_threads = get_adjusted_number_of_threads(cpu_cores) # Get the adjusted number of threads to use

   print(f"{BackgroundColors.GREEN}The number of usable threads is {BackgroundColors.CYAN}{usable_threads}{BackgroundColors.GREEN} out of {BackgroundColors.CYAN}{max_threads}{BackgroundColors.GREEN}.{Style.RESET_ALL}")

   # Function to process each repository
   def process_and_estimate(repository_name, repository_url):
      estimated_time_string = f"{BackgroundColors.GREEN}Estimated time for running all iterations for {BackgroundColors.CYAN}{repository_name}{BackgroundColors.GREEN}: "

      # Traverse commits in the repository and count them without materializing the entire list
      commits_number = sum(1 for _ in Repository(repository_url).traverse_commits()) # Efficient commit count
      estimated_time = round(((commits_number / 1000) * commits_number), 2) # Estimate the time to process the repository
      output_time(estimated_time_string, estimated_time) # Output the estimated time
      process_repository(repository_name, repository_url) # Process the repository

   # Use ThreadPoolExecutor with a limit of usable_threads
   with concurrent.futures.ThreadPoolExecutor(max_workers=usable_threads) as executor:
      futures = [ # Create a list of futures. Futures are used to manage the execution of the function in the thread pool
         executor.submit(process_and_estimate, repository_name, repository_url) # Submit the process_and_estimate function
         for repository_name, repository_url in DEFAULT_REPOSITORIES.items() # Loop through the DEFAULT_REPOSITORIES dictionary
      ]
      concurrent.futures.wait(futures) # Wait for all tasks to complete

# Register the function to play a sound when the program finishes
atexit.register(play_sound)

def main():
   """
   Main function.

   :return: None
   """
   
   # Verify if the path constants contains whitespaces
   if path_contains_whitespaces():
      print(f"{BackgroundColors.RED}The {START_PATH} constant contains whitespaces. Please remove them!{Style.RESET_ALL}")
      return # Return if the path constants contains whitespaces

   global SOUND_FILE_PATH # Declare the SOUND_FILE_PATH as a global variable
   SOUND_FILE_PATH = update_sound_file_path() # Update the sound file path
   
   # Verify if Git is installed
   if not verify_git():
      return # Return if Git is not installed
   
   # Verify if the CK JAR file exists
   if not ensure_ck_jar_file_exists(): # Ensure that the CK JAR file exists
      return # Return if the CK JAR file does not exist

   verify_repositories_execution_constants() # Verify the DEFAULT_REPOSITORIES constant
   
   # Print the welcome message
   print(f"{BackgroundColors.GREEN}Welcome to the {BackgroundColors.CYAN}CK Metrics Generator{BackgroundColors.GREEN}! This script is a key component of the {BackgroundColors.CYAN}Worked Example Miner (WEM) Project{BackgroundColors.GREEN}.{Style.RESET_ALL}")
   print(f"{BackgroundColors.GREEN}This script will process the repositories: {BackgroundColors.CYAN}{json.dumps(list(DEFAULT_REPOSITORIES.keys()))}{BackgroundColors.GREEN} in parallel using threads.{Style.RESET_ALL}")
   print(f"{BackgroundColors.GREEN}The files that this script will generate are the {BackgroundColors.CYAN}ck metrics files, the commit hashes list file and the diffs of each commit{BackgroundColors.GREEN}, in which are used by the {BackgroundColors.CYAN}Metrics Changes{BackgroundColors.GREEN} Python script.{Style.RESET_ALL}", end="\n\n")   

   process_repositories_in_parallel() # Process each of the repositories in parallel

   # Print the message that the CK metrics generator has finished processing the repositories
   print(f"\n{BackgroundColors.GREEN}The {BackgroundColors.CYAN}CK Metrics Generator{BackgroundColors.GREEN} has finished processing the repositories.{Style.RESET_ALL}", end="\n\n")
		
if __name__ == "__main__":
   """
   This is the standard boilerplate that calls the main() function.

   :return: None
   """

   main() # Call the main function
